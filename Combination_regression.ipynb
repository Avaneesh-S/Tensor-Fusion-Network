{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Loading** CMU-MOSI **dataset**"
      ],
      "metadata": {
        "id": "gYs7BSKW5Gqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f80j9mDfld4U",
        "outputId": "7d7ece7a-0dc1-4c0e-eea3-bbec04eccfae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiBench'...\n",
            "remote: Enumerating objects: 6943, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 6943 (delta 72), reused 121 (delta 60), pack-reused 6789\u001b[K\n",
            "Receiving objects: 100% (6943/6943), 51.07 MiB | 22.08 MiB/s, done.\n",
            "Resolving deltas: 100% (4258/4258), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MultiBench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4h7C4XAqNTq",
        "outputId": "6b6a8242-77dd-441c-a757-3448c09c289f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MultiBench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the following cell to download mosi_raw.pkl the data and accordingly add the path while loading the data"
      ],
      "metadata": {
        "id": "q6lAbqlgN1Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!pip install gdown && gdown https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbL-Wu23sEAO",
        "outputId": "8f75f155-8677-417d-9282-fbf25095f3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "DT1jN1eqsJio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the associated dataloader for affect datasets, which MOSI is a part of.\n",
        "from datasets.affect.get_data import get_dataloader\n",
        "\n",
        "# Create the training, validation, and test-set dataloaders.\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=20)"
      ],
      "metadata": {
        "id": "Ye24eAGqsP3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "IFkqO1W-hI9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SubnetModel(nn.Module):\n",
        "    def __init__(self,input_size,num_utterances,fc1_size, fc2_size,fc3_size):\n",
        "        super(SubnetModel, self).__init__()\n",
        "\n",
        "        self.drop = nn.Dropout(p=0.15)\n",
        "\n",
        "        # Fully connected layers\n",
        "\n",
        "        #fc1 gets hidden_size dimension values as input\n",
        "        self.fc1 = nn.Linear(input_size, fc1_size)\n",
        "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
        "        self.fc3 = nn.Linear(fc2_size, fc3_size)\n",
        "\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = torch.mean(x, dim=1)\n",
        "\n",
        "        fc1_out = self.relu(self.fc1(x))\n",
        "        drop1=self.drop(fc1_out)\n",
        "\n",
        "        fc2_out = self.relu(self.fc2(drop1))\n",
        "        drop2=self.drop(fc2_out)\n",
        "\n",
        "        fc3_out=self.relu(self.fc3(drop2))\n",
        "        drop3=self.drop(fc3_out)\n",
        "\n",
        "        return drop3\n",
        "\n"
      ],
      "metadata": {
        "id": "AEkie_f1cqcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class TextModel(nn.Module):\n",
        "    def __init__(self,input_size, hidden_size, num_layers,fc1_size, fc2_size):\n",
        "        super(TextModel, self).__init__()\n",
        "\n",
        "        # LSTM layer (stacked LSTM)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,batch_first=True)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.drop = nn.Dropout(p=0.15)\n",
        "\n",
        "        #fc1 gets hidden_size dimension values as input\n",
        "        self.fc1 = nn.Linear(hidden_size, fc1_size)\n",
        "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        # self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "        # LSTM layer\n",
        "\n",
        "        lstm_out, (hidden_states, cell_states) = self.lstm(x)\n",
        "\n",
        "\n",
        "        fc1_out = self.relu(self.fc1(hidden_states.squeeze()))\n",
        "        # drop1=self.drop(fc1_out)\n",
        "\n",
        "        fc2_out = self.relu(self.fc2(fc1_out))\n",
        "        # drop2=self.drop(fc2_out)\n",
        "\n",
        "        return fc2_out\n"
      ],
      "metadata": {
        "id": "LcVZJRGndvbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class TFN(nn.Module):\n",
        "    def __init__(self,audio_params,video_params,text_params,SIN_params):\n",
        "        super(TFN, self).__init__()\n",
        "\n",
        "        self.output_range = Parameter(torch.FloatTensor([6]), requires_grad=False)\n",
        "        self.output_shift = Parameter(torch.FloatTensor([-3]), requires_grad=False)\n",
        "\n",
        "        self.audio_params=audio_params\n",
        "        self.video_params=video_params\n",
        "        self.text_params=text_params\n",
        "\n",
        "        #unimodels\n",
        "        self.audio_subnet=SubnetModel(audio_params[0],audio_params[1],audio_params[2],audio_params[3],audio_params[4])\n",
        "        self.video_subnet=SubnetModel(video_params[0],video_params[1],video_params[2],video_params[3],video_params[4])\n",
        "        self.text_subnet=TextModel(text_params[0],text_params[1],text_params[2],text_params[3],text_params[4])\n",
        "\n",
        "        # Fully connected layers\n",
        "\n",
        "        self.drop = nn.Dropout(p=0.15)\n",
        "\n",
        "        #fc1 gets hidden_size dimension values as input\n",
        "        self.fc1 = nn.Linear(((audio_params[2]+1)*(video_params[2]+1)*(text_params[3]+1)), SIN_params[0])\n",
        "        self.fc2 = nn.Linear(SIN_params[0], SIN_params[1])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(SIN_params[1], 1)\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        DTYPE = torch.FloatTensor\n",
        "\n",
        "        batch_size=x[0].shape[0]\n",
        "\n",
        "        # unimodal outputs\n",
        "\n",
        "\n",
        "        audio_out=self.audio_subnet(x[0])\n",
        "\n",
        "        video_out=self.video_subnet(x[1])\n",
        "\n",
        "        text_out=self.text_subnet(x[2])\n",
        "\n",
        "\n",
        "\n",
        "        # adding 1 to increase the dimension value\n",
        "\n",
        "        audio_out = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), audio_out), dim=1)\n",
        "        # print(\"audio_out\")\n",
        "        # print(audio_out.shape)\n",
        "        video_out = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), video_out), dim=1)\n",
        "        # print(\"video_out\")\n",
        "        # print(video_out.shape)\n",
        "        text_out = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), text_out), dim=1)\n",
        "        # print(\"text_out\")\n",
        "        # print(text_out.shape)\n",
        "\n",
        "\n",
        "        # tensorfusion operation\n",
        "\n",
        "        fusion_tensor = torch.bmm(audio_out.unsqueeze(2), video_out.unsqueeze(1))\n",
        "\n",
        "        fusion_tensor = fusion_tensor.view(-1, (self.audio_params[2] + 1) * (self.video_params[2] + 1), 1)\n",
        "\n",
        "        fusion_tensor = torch.bmm(fusion_tensor, text_out.unsqueeze(1)).view(batch_size, -1)\n",
        "\n",
        "\n",
        "        fc1_out = self.relu(self.fc1(fusion_tensor))\n",
        "        drop1=self.drop(fc1_out)\n",
        "\n",
        "        fc2_out = self.relu(self.fc2(drop1))\n",
        "        drop2=self.drop(fc2_out)\n",
        "\n",
        "        # Output layer with Sigmoid activation\n",
        "        output = self.sigmoid(self.output_layer(drop2))\n",
        "\n",
        "        # get output between -3 and +3\n",
        "        output=(output*self.output_range)+self.output_shift\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "B0LDfUqSga0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio_out\n",
        "\n",
        "torch.Size([32, 33])\n",
        "\n",
        "then changed to torch.Size([32,33,1])\n",
        "\n",
        "video_out\n",
        "\n",
        "torch.Size([32, 33])\n",
        "\n",
        "then changed to torch.Size([32,1,33])\n",
        "\n",
        "text_out\n",
        "\n",
        "torch.Size([32, 129])\n",
        "\n",
        "fusion tensor 1\n",
        "\n",
        "torch.Size([32, 33, 33])\n",
        "\n",
        "fusion tensor 2\n",
        "\n",
        "torch.Size([32, 1089, 1])\n",
        "\n",
        "fusion tensor 3\n",
        "\n",
        "first changed text_out to torch.Size([32,1,129]) then bmm with fusion tensor 2\n",
        "\n",
        "we get torch.Size([32,1089,129]) which is then flattened to:\n",
        "\n",
        "torch.Size([32, 140481]) to feed to fully connected network\n",
        "\n",
        "which is torch.Size([32,129x33x33])"
      ],
      "metadata": {
        "id": "GM5QzJGBCaYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-------------------------------------------------------------------------------------------------------------------------------------**"
      ],
      "metadata": {
        "id": "Vf3Zk87ghD2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len=50\n",
        "\n",
        "audio_params=(35,max_seq_len,32,32,32) # (feature_length,max_seq_len,fc1_size,fc2_size,fc3_size)\n",
        "video_params=(74,max_seq_len,32,32,32) # (feature_length,max_seq_len,fc1_size,fc2_size,fc3_size)\n",
        "text_params=(300,128,1,128,128) # (feature_length,LSTM_hidden_size,num_LSTM_layers,fc1_size,fc2_size)\n",
        "\n",
        "SIN_params=(128,128)\n",
        "\n",
        "final_model=TFN(audio_params,video_params,text_params,SIN_params)"
      ],
      "metadata": {
        "id": "Cv6JFvPMo9Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading weights of saved model"
      ],
      "metadata": {
        "id": "1YObAFSTrCwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final_model.load_state_dict(torch.load('/content/drive/MyDrive/multi_model_SA/TFN_MAE-1.4939_50epochs.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP0ml0g0rEwg",
        "outputId": "311fd76b-e04b-4436-e6b3-4ec3f2b9ad90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Loss = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(list(final_model.parameters())[2:],lr=5e-4,weight_decay=0.01)\n",
        "num_epochs = 20\n",
        "testdata=validdata"
      ],
      "metadata": {
        "id": "n_C-rC-Itq9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import scipy.stats"
      ],
      "metadata": {
        "id": "6eAovmM4tcIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "IjTTSwbwkv20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    print(\"EPOCH : \",epoch+1)\n",
        "    # Training\n",
        "    total_train_loss=0.0\n",
        "    num_sequences=0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    final_model.train()  # Set the model to training mode\n",
        "    for batch in traindata:\n",
        "        # targets=targets.unsqueeze(1).repeat(1, 50, 1)\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        labels=batch[-1]\n",
        "        outputs = final_model(batch[:-1])\n",
        "        loss = Loss(outputs, batch[-1])\n",
        "\n",
        "        total_train_loss+=loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        all_predictions.extend(outputs)\n",
        "        all_targets.extend(labels)\n",
        "        num_sequences+=1\n",
        "\n",
        "    all_predictions = np.array([tensor.detach().numpy() for tensor in all_predictions])\n",
        "    all_targets = np.array([tensor.detach().numpy() for tensor in all_targets])\n",
        "\n",
        "    average_train_loss = total_train_loss / num_sequences\n",
        "    train_mae= mean_absolute_error(all_targets, all_predictions)\n",
        "    r = scipy.stats.pearsonr(all_targets.ravel(), all_predictions.ravel())\n",
        "    print(\"-------------Training----------------\")\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}],MAE:{train_mae:.4f} ,r:{r[0]:.4f}')\n",
        "\n",
        "    # Validation\n",
        "    final_model.eval()  # Set the model to evaluation mode\n",
        "    total_val_loss = 0.0\n",
        "    num_sequences=0\n",
        "    val_all_predictions = []\n",
        "    val_all_targets = []\n",
        "    with torch.no_grad():\n",
        "        best_val_loss = np.inf\n",
        "        patience=3\n",
        "        current_patience = patience\n",
        "\n",
        "        for batch in validdata:\n",
        "            val_targets=batch[-1]\n",
        "            val_outputs = final_model(batch[:-1])\n",
        "            val_loss = Loss(val_outputs, val_targets)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "\n",
        "            val_all_predictions.extend(val_outputs)\n",
        "            val_all_targets.extend(val_targets)\n",
        "            num_sequences+=1\n",
        "\n",
        "    average_val_loss = total_val_loss / num_sequences\n",
        "    val_all_predictions=np.array(val_all_predictions)\n",
        "    val_all_targets=np.array(val_all_targets)\n",
        "    mae = mean_absolute_error(val_all_targets, val_all_predictions)\n",
        "    val_r = scipy.stats.pearsonr(val_all_targets.ravel(), val_all_predictions.ravel())\n",
        "\n",
        "\n",
        "\n",
        "    print(\"--------------Validation----------\")\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}],mae: {mae:.4f},r:{val_r[0]:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n \\n\")\n"
      ],
      "metadata": {
        "id": "PHS0TU9AtcIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "72ac762f-ce86-4952-9548-098b71068c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH :  1\n",
            "-------------Training----------------\n",
            "Epoch [1/20],MAE:0.7249 ,r:0.7849\n",
            "--------------Validation----------\n",
            "Epoch [1/20],mae: 1.1092,r:0.5312\n",
            "\n",
            " \n",
            "\n",
            "EPOCH :  2\n",
            "-------------Training----------------\n",
            "Epoch [2/20],MAE:0.7104 ,r:0.7957\n",
            "--------------Validation----------\n",
            "Epoch [2/20],mae: 1.0841,r:0.5393\n",
            "\n",
            " \n",
            "\n",
            "EPOCH :  3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ae6f10fd484a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zero the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-71ee4b7f20a5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mvideo_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtext_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6a5006c68294>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# last_time_step_index = lstm_out.size(1) - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    879\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "final_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch in testdata:\n",
        "        test_targets=batch[-1]\n",
        "        test_outputs = final_model(batch[:-1])\n",
        "\n",
        "        all_predictions.extend(test_outputs)\n",
        "        all_targets.extend(test_targets)\n",
        "\n",
        "    all_predictions=np.array(all_predictions)\n",
        "    all_targets=np.array(all_targets)\n",
        "    mae = mean_absolute_error(all_targets, all_predictions)\n",
        "    r =  scipy.stats.pearsonr(all_targets.ravel(), all_predictions.ravel())\n",
        "\n",
        "    print(f'Test MAE: {mae:.4f} , r:{r[0]:.4f}')\n"
      ],
      "metadata": {
        "id": "eK1pV2IPtcIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fb76a8-0f6f-472c-c101-6bbdd9eb827d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE: 1.1014 , r:0.5282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "k9fPZKKktgNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "qt2MvMvXth_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **keeping everything according to paper:**\n",
        "\n",
        "1) lr=0.0005 , weight_decay=0.01 , 100 epochs(50/100) - mae = 1.28 on val and 1.49 on test\n",
        "\n",
        "### **not keeping everything same as paper:**\n",
        "\n",
        "added dropout to text subnetwork along with others\n",
        "\n",
        "1) lr=0.0005 , weight_decay=0.01 , 100 epochs(40/100) - mae = 1.33 on val and 1.54 on test\n",
        "\n",
        "added dropout to text subnetwork and removed from sentiment\n",
        "\n",
        "2) lr=0.0005 , weight_decay=0.01 , 100 epochs(40/100) - mae = 1.34 on val and 1.55 on test"
      ],
      "metadata": {
        "id": "1sxfFGetBw4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model:\n"
      ],
      "metadata": {
        "id": "k2WUXu0OYyqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(final_model.state_dict(), '/content/drive/MyDrive/multi_model_SA/TFN_regression')"
      ],
      "metadata": {
        "id": "P8Rlev7zY02x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(final_model.state_dict(), '/content/drive/MyDrive/multi_model_SA/TFN_MAE-1.4939_50epochs.pth')"
      ],
      "metadata": {
        "id": "w-1AKsBPh_nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------"
      ],
      "metadata": {
        "id": "t5wYH_ThV2nt"
      }
    }
  ]
}